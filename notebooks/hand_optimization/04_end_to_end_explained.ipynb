{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7827866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beartype ensures that the code is type-checked at runtime\n",
    "%load_ext ipython_beartype\n",
    "%beartype\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2caa0e5",
   "metadata": {},
   "source": [
    "# Project Goal\n",
    "\n",
    "![Motion-retargeting overview](../../media/motion-retargeting.png)\n",
    "\n",
    "\n",
    "Build an easy to setup end-to-end pipeline that converts **time-synced multi-camera footage** into **axis‚Äìangle joint angles + metric 3-D positions** of every finger joint.  \n",
    "This dataset becomes plug-and-play ‚Äúmotion fuel‚Äù for:\n",
    "\n",
    "* **Robotic retargeting** ‚Äì Drive anthropomorphic or multi-finger grippers directly from human demonstrations.  \n",
    "* **Learning fine motor skills** ‚Äì High-resolution, constraint-aware labels let models capture subtle grasps, in-hand manipulation, and tactile exploration‚Äîmovements that raw meshes or XYZ clouds alone fail to encode.\n",
    "\n",
    "In short, precise joint angles are the missing link between human dexterity and robot hands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5109cb1d",
   "metadata": {},
   "source": [
    "### Why do we need a kinematic skeleton with joint angles?\n",
    "\n",
    "- **Rig-agnostic pose** ‚Äì Captures only relative bone rotations, so the same grasp can be transfered to any avatar or robot hand.  \n",
    "- **Easy retargeting** ‚Äì A single FK pass transfers motion to MANO, MediaPipe, game rigs, or grippers.  \n",
    "- **Tiny storage** ‚Äì 20 joints √ó 3 floats ‚âà 60 numbers per frame‚Äîorders of magnitude smaller than meshes.  \n",
    "- **Built-in constraints** ‚Äì Bone lengths, joint limits, and couplings are trivial to enforce in angle space.  \n",
    "- **Gradient-friendly** ‚Äì FK is differentiable, enabling fast optimisation from 2-D reprojection errors.  \n",
    "- **Sensor fusion-ready** ‚Äì IMUs, mocap markers, or language commands map cleanly into the same angles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a44469",
   "metadata": {},
   "source": [
    "### Capture-to-Angles Pipeline  \n",
    "**Input :** time-synced, calibrated cameras (intrinsics + extrinsics)  \n",
    "**Output :** axis‚Äìangle joint angles **Œ∏** + 3-D joint positions in meters\n",
    "\n",
    "| Step | Input | Process | Output |\n",
    "|------|-------|---------|--------|\n",
    "| 1 | RGB frames | 2-D keypoint detector | Pixel joints |\n",
    "| 2 | Pixel joints + cams | Triangulation / PnP | 3-D joints (m) |\n",
    "| 3 | 3-D joints | Inverse kinematics | Axis-angle **Œ∏** |\n",
    "| 4 | **Œ∏** | FK sanity check | Rebuilt 3-D joints |\n",
    "| 5 | **Œ∏**, 3-D joints | Serialize | **Œ∏** + xyz (m) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364167d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-05-02 14:15:56,494:jax._src.xla_bridge:909: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "# Add these lines to the cell with id 34bb5824\n",
    "import warnings\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import rerun as rr\n",
    "from jaxtyping import Array, Float\n",
    "from simplecv.data.exoego.skeleton.mediapipe import MEDIAPIPE_ID2NAME, MEDIAPIPE_IDS, MEDIAPIPE_LINKS\n",
    "\n",
    "from pi0_lerobot.mano.mano_optimization_jax import HandSide\n",
    "from pi0_lerobot.skeletons.coco_133 import COCO_133_ID2NAME, COCO_133_IDS, COCO_133_LINKS\n",
    "\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30fc666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helps provide context for the rerun viewer, to visualize the difference between triangulated and optimized hand joints\n",
    "def set_pose_annotation_context() -> None:\n",
    "    rr.log(\n",
    "        \"/\",\n",
    "        rr.AnnotationContext(\n",
    "            [\n",
    "                rr.ClassDescription(\n",
    "                    info=rr.AnnotationInfo(id=0, label=\"Triangulated Hand\", color=(0, 0, 255)),\n",
    "                    keypoint_annotations=[\n",
    "                        rr.AnnotationInfo(id=id, label=name) for id, name in MEDIAPIPE_ID2NAME.items()\n",
    "                    ],\n",
    "                    keypoint_connections=MEDIAPIPE_LINKS,\n",
    "                ),\n",
    "                rr.ClassDescription(\n",
    "                    info=rr.AnnotationInfo(id=1, label=\"Optimized Hand\", color=(255, 0, 0)),\n",
    "                    keypoint_annotations=[\n",
    "                        rr.AnnotationInfo(id=id, label=name) for id, name in MEDIAPIPE_ID2NAME.items()\n",
    "                    ],\n",
    "                    keypoint_connections=MEDIAPIPE_LINKS,\n",
    "                ),\n",
    "                rr.ClassDescription(\n",
    "                    info=rr.AnnotationInfo(id=2, label=\"Wholebody 133\", color=(0, 0, 0)),\n",
    "                    keypoint_annotations=[\n",
    "                        rr.AnnotationInfo(id=id, label=name) for id, name in COCO_133_ID2NAME.items()\n",
    "                    ],\n",
    "                    keypoint_connections=COCO_133_LINKS,\n",
    "                ),\n",
    "            \n",
    "            ]\n",
    "        ),\n",
    "        static=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970a448",
   "metadata": {},
   "source": [
    "### Example dataset ‚Äì HO-Cap\n",
    "\n",
    "We‚Äôll use the [HO-Cap](https://irvlutd.github.io/HOCap/) dataset, which ships with:\n",
    "\n",
    "- ‚è± Time-synchronized RGB videos  \n",
    "- üì∑ Camera intrinsics **K** and extrinsics **R | t**  \n",
    "- üéØ 2-D + 3-D hand keypoints (pixels / meters)  \n",
    "- ‚úã MANO parameters (shape Œ≤, joint angles Œ∏)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9836b110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HoloLens camera: hololens_kv5h72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading videos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 32017.59it/s]\n",
      "Loading 3D labels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:02<00:00,  3.72it/s]\n",
      "Indexing depth images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 450.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from jaxtyping import Float32, UInt8\n",
    "from numpy import ndarray\n",
    "from rerun.blueprint import Blueprint\n",
    "from simplecv.apis.view_exoego_data import create_blueprint\n",
    "from simplecv.camera_parameters import PinholeParameters\n",
    "from simplecv.data.exoego.base_exo_ego import ExoData\n",
    "from simplecv.data.exoego.hocap import HOCapSequence\n",
    "from simplecv.rerun_log_utils import log_pinhole\n",
    "\n",
    "data_path = Path(\"../../data/hocap/sample\")\n",
    "assert data_path.exists(), f\"Data path {data_path} does not exist, please check the path.\"\n",
    "sequence: HOCapSequence = HOCapSequence(\n",
    "    data_path=data_path,\n",
    "    sequence_name=\"20231024_180733\",\n",
    "    subject_id=\"8\",\n",
    "    load_labels=True,\n",
    ")\n",
    "\n",
    "parent_log_path: Path = Path(\"world\")\n",
    "\n",
    "exo_cam_log_paths: list[Path] = [parent_log_path / exo_cam.name for exo_cam in sequence.exo_cam_list]\n",
    "exo_video_log_paths: list[Path] = [cam_log_paths / \"pinhole\" / \"video\" for cam_log_paths in exo_cam_log_paths]\n",
    "\n",
    "blueprint: Blueprint = create_blueprint(exo_video_log_paths=exo_video_log_paths, num_videos_to_log=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f62f53",
   "metadata": {},
   "source": [
    "## Visualize the first 50 frames of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c8611f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf0f476be6741a6835ee7109fe9a1ae",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Viewer()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Timed out waiting for viewer to become ready. Make sure: https://app.rerun.io/version/0.23.1/widget.js is accessible.\n",
      "If not, consider setting `RERUN_NOTEBOOK_ASSET`. Consult https://pypi.org/project/rerun-notebook/0.23.1/ for details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from typing import Literal\n",
    "\n",
    "rr.init(\"sequence data\")\n",
    "set_pose_annotation_context()\n",
    "rr.notebook_show(width=1000, height=700, blueprint=blueprint)\n",
    "\n",
    "num_frames: int = 50\n",
    "\n",
    "exo_data: ExoData\n",
    "for idx, exo_data in enumerate(itertools.islice(sequence, num_frames)):\n",
    "    rr.set_time(\"frame idx\",sequence=idx)\n",
    "    for hand_enum in HandSide:\n",
    "        hand_side: Literal[\"left\", \"right\"] = hand_enum.name.lower()\n",
    "        hand_idx: int = hand_enum.value\n",
    "        \n",
    "        xyz_gt: Float32[ndarray, \"21 3\"] = exo_data.xyz[hand_idx]\n",
    "\n",
    "        rr.log(\n",
    "            hand_side,\n",
    "            rr.Points3D(\n",
    "                xyz_gt,\n",
    "                colors=(0, 255, 0),\n",
    "                class_ids=0,\n",
    "                keypoint_ids=MEDIAPIPE_IDS,\n",
    "                show_labels=False,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    for cam_param, bgr in zip(exo_data.cam_params_list, exo_data.bgr_list, strict=True):\n",
    "        cam_log_path: Path = parent_log_path / cam_param.name   \n",
    "        image_log_path: Path = cam_log_path / \"pinhole\" / \"video\"\n",
    "        # camera parameters don't change, so we can log them once\n",
    "        if idx == 0:\n",
    "            log_pinhole(\n",
    "                        camera=cam_param,\n",
    "                        cam_log_path=cam_log_path,\n",
    "                        image_plane_distance=0.1,\n",
    "                        static=True\n",
    "                    )\n",
    "        rr.log(\n",
    "            f\"{image_log_path}\",\n",
    "            rr.Image(\n",
    "                bgr,\n",
    "                color_model=rr.ColorModel.BGR\n",
    "            ).compress(jpeg_quality=15),\n",
    "        )\n",
    "        for hand_enum in HandSide:\n",
    "            hand_side: Literal[\"left\", \"right\"] = hand_enum.name.lower() # Get \"left\" or \"right\"\n",
    "            hand_idx: int = hand_enum.value\n",
    "\n",
    "            xyz_gt: Float32[ndarray, \"21 3\"] = exo_data.xyz[hand_idx]\n",
    "            # np.nan is used to indicate that a joint is not confidently detected\n",
    "            uv: Float32[ndarray, \"21 2\"] = exo_data.uv_dict[cam_param.name][hand_idx]\n",
    "            # np.nan is used to indicate that a joint is not confidently detected\n",
    "            uv[uv == -1] = np.nan\n",
    "\n",
    "            # find min/max to generate a bounding box, add a small padding\n",
    "            uv_min:Float32[ndarray, \"2\"] = np.nanmin(uv, axis=0)\n",
    "            uv_max:Float32[ndarray, \"2\"] = np.nanmax(uv, axis=0)\n",
    "\n",
    "            xyxy:Float32[ndarray, \"4\"] = np.concatenate([uv_min, uv_max], axis=0)\n",
    "            # if nan skip logging keypoints and bboxes\n",
    "            if np.any(np.isnan(xyxy)):\n",
    "                continue\n",
    "\n",
    "            # keypoints\n",
    "            rr.log(\n",
    "                f\"{image_log_path}/{hand_side}_keypoints\",\n",
    "                rr.Points2D(\n",
    "                    uv,\n",
    "                    colors=(0, 255, 0),\n",
    "                    class_ids=0,\n",
    "                    keypoint_ids=MEDIAPIPE_IDS,\n",
    "                    show_labels=False,\n",
    "                ),\n",
    "            )\n",
    "            # bounding boxes\n",
    "            rr.log(\n",
    "                    f\"{image_log_path}/{hand_side}_xyxy\",\n",
    "                    rr.Boxes2D(\n",
    "                        array=xyxy,\n",
    "                        array_format=rr.Box2DFormat.XYXY,\n",
    "                        labels=[hand_side],\n",
    "                    )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759533a5",
   "metadata": {},
   "source": [
    "## 1. RGB Frames -> 2D Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b080f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load /home/pablo/.cache/rtmlib/hub/checkpoints/yolox_m_8xb8-300e_humanart-c2c7a14a.onnx with onnxruntime backend\n",
      "load /home/pablo/.cache/rtmlib/hub/checkpoints/rtmw-dw-x-l_simcc-cocktail14_270e-384x288_20231122.onnx with onnxruntime backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-05-02 14:16:12.009910146 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2025-05-02 14:16:12.009924173 [W:onnxruntime:, session_state.cc:1170 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n",
      "\u001b[0;93m2025-05-02 14:16:12.092018376 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer '1701'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-05-02 14:16:12.092040427 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer '1706'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-05-02 14:16:12.092050196 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer '1709'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-05-02 14:16:12.099701974 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2025-05-02 14:16:12.099708716 [W:onnxruntime:, session_state.cc:1170 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12aa08c6a2f446cfbc90efa3505f37c1",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Viewer()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Timed out waiting for viewer to become ready. Make sure: https://app.rerun.io/version/0.23.1/widget.js is accessible.\n",
      "If not, consider setting `RERUN_NOTEBOOK_ASSET`. Consult https://pypi.org/project/rerun-notebook/0.23.1/ for details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import rerun.blueprint as rrb\n",
    "from rtmlib import Wholebody\n",
    "\n",
    "device = 'cuda'  # cpu, cuda, mps\n",
    "backend = 'onnxruntime'  # opencv, onnxruntime, openvino\n",
    "\n",
    "wholebody = Wholebody(to_openpose=False,\n",
    "                      mode='performance',  # 'performance', 'lightweight', 'balanced'. Default: 'balanced'\n",
    "                      backend=backend, device=device)\n",
    "\n",
    "bgr: UInt8[ndarray, \"H W 3\"] = exo_data.bgr_list[-1]\n",
    "wb_output:tuple[Float[ndarray, \"...\"], Float[ndarray, \"...\"]] = wholebody(bgr)\n",
    "\n",
    "keypoints: Float[ndarray, \"n_dets 133 2\"] = wb_output[0]\n",
    "scores: Float[ndarray, \"n_dets 133\"] = wb_output[1]\n",
    "uvc: Float[ndarray, \"n_dets 133 3\"] = np.concatenate(\n",
    "    [keypoints, scores[..., np.newaxis]], axis=-1\n",
    ")\n",
    "\n",
    "LEFT_START_IDX: int = 112\n",
    "RIGHT_START_IDX: int = 91\n",
    "left_hand: Float[ndarray, \"n_dets 21 3\"] = uvc[:, LEFT_START_IDX:LEFT_START_IDX+21, :]\n",
    "right_hand: Float[ndarray, \"n_dets 21 3\"] = uvc[:, RIGHT_START_IDX:RIGHT_START_IDX+21, :]\n",
    "\n",
    "\n",
    "minimal_blueprint = rrb.Blueprint(collapse_panels=True)\n",
    "\n",
    "rr.init(\"2D keypoints\")\n",
    "set_pose_annotation_context()\n",
    "rr.notebook_show(width=1000, height=700, blueprint=minimal_blueprint)\n",
    "\n",
    "rr.log(\n",
    "    \"image\",\n",
    "    rr.Image(\n",
    "        bgr,\n",
    "        color_model=rr.ColorModel.BGR\n",
    "    ).compress(jpeg_quality=15),\n",
    ")\n",
    "\n",
    "rr.log(\n",
    "    \"image/2d_keypoints\",\n",
    "    rr.Points2D(\n",
    "        uvc[0, :, :2],\n",
    "        colors=(0, 255, 0),\n",
    "        class_ids=2,\n",
    "        keypoint_ids=COCO_133_IDS,\n",
    "        show_labels=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "rr.log(\n",
    "    \"image/left_hand_keypoints\",\n",
    "    rr.Points2D(\n",
    "        left_hand[0, :, :2],\n",
    "        colors=(255, 0, 0),\n",
    "        class_ids=0,\n",
    "        keypoint_ids=MEDIAPIPE_IDS,\n",
    "        show_labels=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "rr.log(\n",
    "    \"image/right_hand_keypoints\",\n",
    "    rr.Points2D(\n",
    "        right_hand[0, :, :2],\n",
    "        colors=(255, 0, 0),\n",
    "        class_ids=0,\n",
    "        keypoint_ids=MEDIAPIPE_IDS,\n",
    "        show_labels=False,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939e99ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3fec89b359475f80eb564e45f18e99",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Viewer()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Timed out waiting for viewer to become ready. Make sure: https://app.rerun.io/version/0.23.1/widget.js is accessible.\n",
      "If not, consider setting `RERUN_NOTEBOOK_ASSET`. Consult https://pypi.org/project/rerun-notebook/0.23.1/ for details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rr.init(\"2D keypoints\")\n",
    "set_pose_annotation_context()\n",
    "rr.notebook_show(width=1000, height=700, blueprint=minimal_blueprint)\n",
    "\n",
    "for idx, exo_data in enumerate(itertools.islice(sequence, 150)):\n",
    "    rr.set_time(\"frame idx\",sequence=idx)\n",
    "    bgr = exo_data.bgr_list[-1]\n",
    "\n",
    "    wb_output:tuple[Float[ndarray, \"...\"], Float[ndarray, \"...\"]] = wholebody(bgr)\n",
    "\n",
    "    keypoints: Float[ndarray, \"n_dets 133 2\"] = wb_output[0]\n",
    "    scores: Float[ndarray, \"n_dets 133\"] = wb_output[1]\n",
    "    uvc: Float[ndarray, \"n_dets 133 3\"] = np.concatenate(\n",
    "        [keypoints, scores[..., np.newaxis]], axis=-1\n",
    "    )\n",
    "\n",
    "    left_hand: Float[ndarray, \"n_dets 21 3\"] = uvc[:, LEFT_START_IDX:LEFT_START_IDX+21, :]\n",
    "    right_hand: Float[ndarray, \"n_dets 21 3\"] = uvc[:, RIGHT_START_IDX:RIGHT_START_IDX+21, :]\n",
    "\n",
    "\n",
    "    rr.log(\n",
    "        \"image\",\n",
    "        rr.Image(\n",
    "            bgr,\n",
    "            color_model=rr.ColorModel.BGR\n",
    "        ).compress(jpeg_quality=15),\n",
    "    )\n",
    "\n",
    "    rr.log(\n",
    "        \"image/left_hand_keypoints\",\n",
    "        rr.Points2D(\n",
    "            left_hand[0, :, :2],\n",
    "            colors=(255, 0, 0),\n",
    "            class_ids=0,\n",
    "            keypoint_ids=MEDIAPIPE_IDS,\n",
    "            show_labels=False,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    rr.log(\n",
    "        \"image/right_hand_keypoints\",\n",
    "        rr.Points2D(\n",
    "            right_hand[0, :, :2],\n",
    "            colors=(0, 255, 0),\n",
    "            class_ids=0,\n",
    "            keypoint_ids=MEDIAPIPE_IDS,\n",
    "            show_labels=False,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdab0ebc",
   "metadata": {},
   "source": [
    "## 2. 3D triangulated keypoints on the first frame\n",
    "\n",
    "For the sake of simplicity, we'll use the provided 3D keypoints form the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01da55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c83171a3664ee39ae7a7026a2d5803",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Viewer()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Timed out waiting for viewer to become ready. Make sure: https://app.rerun.io/version/0.23.1/widget.js is accessible.\n",
      "If not, consider setting `RERUN_NOTEBOOK_ASSET`. Consult https://pypi.org/project/rerun-notebook/0.23.1/ for details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the ExoData for the selected frames\n",
    "exo_data: ExoData = sequence[0]\n",
    "xyz_gt: Float[ndarray, \"2 21 3\"] = exo_data.xyz\n",
    "xyz_template_left: Float[ndarray, \"21 3\"] = xyz_gt[0]\n",
    "xyz_template_right: Float[ndarray, \"21 3\"] = xyz_gt[1]\n",
    "\n",
    "# log triangulated points\n",
    "rr.init(\"3D Triangulated\")\n",
    "set_pose_annotation_context()\n",
    "rr.notebook_show(width=1000, height=700, blueprint=minimal_blueprint)\n",
    "\n",
    "for hand_enum in HandSide:\n",
    "    hand_side: Literal[\"left\", \"right\"] = hand_enum.name.lower()\n",
    "    hand_idx: int = hand_enum.value\n",
    "    rr.log(\n",
    "        f\"image/gt_{hand_side}\",\n",
    "        rr.Points3D(\n",
    "            xyz_gt[hand_idx],\n",
    "            colors=(0, 255, 0),\n",
    "            class_ids=0,\n",
    "            keypoint_ids=MEDIAPIPE_IDS,\n",
    "            show_labels=False,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f96314",
   "metadata": {},
   "source": [
    "## 3. Kinematic Skeleton\n",
    "\n",
    "With initial xyz keypoints, we'll use these to set the joint lengths in the kinematic skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54a7f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit\n",
    "\n",
    "from pi0_lerobot.mano.mano_jax import JointsOnly, mp_to_mano\n",
    "\n",
    "# --- Knematic Skeleton Setup ---\n",
    "# JIT compile the MANO function for performance\n",
    "xyz_left_gt: Float[Array, \"21 3\"] = jnp.array(xyz_template_left[mp_to_mano, :])\n",
    "left_joints = JointsOnly(template_joints=xyz_left_gt)\n",
    "left_joints_jit = jit(left_joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e152b8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "/* slider label text */\n",
       ".widget-label {\n",
       "    color: #ffffff !important;\n",
       "}\n",
       "\n",
       "/* numeric readout on the right side of sliders */\n",
       ".widget-readout {\n",
       "    color: #ffffff !important;\n",
       "}\n",
       "\n",
       "/* optional: make the thumb pop on dark backgrounds */\n",
       ".jupyter-widgets input[type=range]::-webkit-slider-thumb {\n",
       "    border: 2px solid #ffffff;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a11c3cfd154b3badf6e1aed9f2d2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), GridBox(children=(FloatSlider(value=0.0, description='Global Rot Axis 0', layout=Layo‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML, display\n",
    "from rerun.notebook import Viewer\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "/* slider label text */\n",
    ".widget-label {\n",
    "    color: #ffffff !important;\n",
    "}\n",
    "\n",
    "/* numeric readout on the right side of sliders */\n",
    ".widget-readout {\n",
    "    color: #ffffff !important;\n",
    "}\n",
    "\n",
    "/* optional: make the thumb pop on dark backgrounds */\n",
    ".jupyter-widgets input[type=range]::-webkit-slider-thumb {\n",
    "    border: 2px solid #ffffff;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "# Set the logging level for the root logger to ERROR to suppress WARNING messages\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "# --- Rerun Initialization ---\n",
    "rr.init(\"mano_sliders_example\")\n",
    "viewer = Viewer(height=600, width=800)\n",
    "\n",
    "\n",
    "rr.set_time(\"time\", sequence=0)\n",
    "set_pose_annotation_context()\n",
    "rr.send_blueprint(minimal_blueprint)\n",
    "\n",
    "# --- MANO Joint Name Mapping ---\n",
    "# Derived from MEDIAPIPE_ID2NAME and mp_to_mano provided by user\n",
    "# This maps the MANO *pose parameter* joint index (1-15) to its name\n",
    "MANO_POSE_JOINT_ID2NAME = {\n",
    "    1: \"INDEX_MCP\",  # MANO index 1 (mp 5)\n",
    "    2: \"INDEX_PIP\",  # MANO index 2 (mp 6)\n",
    "    3: \"INDEX_DIP\",  # MANO index 3 (mp 7)\n",
    "    4: \"MIDDLE_MCP\", # MANO index 4 (mp 9)\n",
    "    5: \"MIDDLE_PIP\", # MANO index 5 (mp 10)\n",
    "    6: \"MIDDLE_DIP\", # MANO index 6 (mp 11)\n",
    "    7: \"PINKY_MCP\",  # MANO index 7 (mp 17)\n",
    "    8: \"PINKY_PIP\",  # MANO index 8 (mp 18)\n",
    "    9: \"PINKY_DIP\",  # MANO index 9 (mp 19)\n",
    "    10: \"RING_MCP\",  # MANO index 10 (mp 13)\n",
    "    11: \"RING_PIP\",  # MANO index 11 (mp 14)\n",
    "    12: \"RING_DIP\",  # MANO index 12 (mp 15)\n",
    "    13: \"THUMB_MCP\", # MANO index 13 (mp 1) - Note: MP calls this CMC\n",
    "    14: \"THUMB_PIP\", # MANO index 14 (mp 2) - Note: MP calls this MCP\n",
    "    15: \"THUMB_IP\",  # MANO index 15 (mp 3) - Note: MP calls this IP\n",
    "}\n",
    "\n",
    "# --- Slider Creation (48 sliders) ---\n",
    "\n",
    "sliders = []\n",
    "for i in range(48):\n",
    "    # First 3 are global rotation, rest are joint rotations\n",
    "    if i < 3:\n",
    "        description = f'Global Rot Axis {i}'\n",
    "    else:\n",
    "        joint_idx = (i - 3) // 3 + 1\n",
    "        axis_idx = (i - 3) % 3\n",
    "        joint_name = MANO_POSE_JOINT_ID2NAME.get(joint_idx, f'Joint {joint_idx}') # Use name or fallback\n",
    "        description = f'{joint_name} Axis {axis_idx}'\n",
    "    \n",
    "    sliders.append(widgets.FloatSlider(\n",
    "            min=-3.14, \n",
    "            max=3.14, \n",
    "            step=0.01, \n",
    "            value=0.0, \n",
    "            description=description,\n",
    "            continuous_update=True, # Only update when slider released\n",
    "            layout=widgets.Layout(width='200px'), # Reduced width\n",
    "        ))\n",
    "\n",
    "# --- Update Function ---\n",
    "def update_mano(change=None):\n",
    "    # Gather slider values\n",
    "    pose_coeffs_list = [s.value for s in sliders]\n",
    "    pose_coeffs = jnp.array(pose_coeffs_list).reshape(1, 48)\n",
    "    \n",
    "    # Define default translation (can be made interactive too if needed)\n",
    "    trans = jnp.zeros((1, 1, 3))\n",
    "    \n",
    "    # Run MANO forward kinematics\n",
    "    keypoints = left_joints_jit(pose_coeffs, trans) # Use JIT compiled version\n",
    "    keypoints_np: Float[ndarray, \"21 3\"] = np.array(keypoints[0])  # Extract the first batch\n",
    "    \n",
    "    # Log to Rerun (convert JAX array to NumPy for Rerun)\n",
    "    rr.log(\"world/mano_joints\",\n",
    "           rr.Points3D(\n",
    "               positions=keypoints_np,\n",
    "               colors=(0, 255, 0),\n",
    "               class_ids=0,\n",
    "               keypoint_ids=MEDIAPIPE_IDS,\n",
    "               show_labels=False, )) # Adjusted radius\n",
    "\n",
    "# --- Observe Sliders ---\n",
    "for slider in sliders:\n",
    "    slider.observe(update_mano, names='value')\n",
    "\n",
    "# --- Layout ---\n",
    "# Arrange sliders in a grid (e.g., 16 rows, 3 columns)\n",
    "slider_grid = widgets.GridBox(sliders, layout=widgets.Layout(\n",
    "    grid_template_columns='repeat(3, 220px)', # Reduced column width\n",
    "    grid_gap='2px 5px' # Reduced gap between sliders\n",
    "))\n",
    "\n",
    "# Capture viewer display\n",
    "viewer_output = widgets.Output()\n",
    "with viewer_output:\n",
    "    display(viewer)\n",
    "\n",
    "# Combine viewer and sliders (viewer on left, sliders on right)\n",
    "ui_layout = widgets.HBox([viewer_output, slider_grid])\n",
    "\n",
    "# --- Initial Log & Display ---\n",
    "update_mano() # Log the initial pose (all zeros)\n",
    "display(ui_layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506977ef",
   "metadata": {},
   "source": [
    "## Example Optimization on a single timestep using multiview 2d keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "808a9bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/0Dev/repos/pi0-lerobot/.pixi/envs/default/lib/python3.11/site-packages/jaxopt/_src/levenberg_marquardt.py:506: UserWarning: The linear solver cholesky that requires materialization of J^T.J matrix is used with materialize_jac=False, which may cause a computational overhead. Consider using either a matrix-free iterative solver such as cg or bicg or using materialize_jac=True.\n",
      "  warnings.warn(f\"The linear solver {self.solver} that requires materialization of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing JIT, can take a while...\n",
      "Trace Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee1762a91a24a029494227d9e9abf8a",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Viewer()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jaxopt._src.levenberg_marquardt import LevenbergMarquardtState\n",
    "\n",
    "from pi0_lerobot.mano.mano_optimization_jax import (\n",
    "    JointAndScaleOptimization,\n",
    "    LossWeights,\n",
    "    OptimizationResults,\n",
    "    proj_3d_vectorized,\n",
    ")\n",
    "\n",
    "loss_weights = LossWeights(\n",
    "    keypoint_2d=0.1,\n",
    "    depth=0.0,\n",
    "    temp=0.0,\n",
    ")\n",
    "\n",
    "exo_data_list: list[ExoData] = [sequence[50]]\n",
    "\n",
    "P_list: list[Float[ndarray, \"3 4\"]] = [exo_cam.projection_matrix for exo_cam in exo_data_list[0].cam_params_list]\n",
    "Pall: Float[ndarray, \"n_views 3 4\"] = np.stack(P_list, axis=0)\n",
    "\n",
    "new_joint_and_scale_optimizer = JointAndScaleOptimization(\n",
    "    xyz_template=np.stack([xyz_template_left, xyz_template_right], axis=0),\n",
    "    Pall=Pall,\n",
    "    loss_weights=loss_weights,\n",
    "    num_iters=30)\n",
    "\n",
    "rr.init(\"Optimization over sequence data\")\n",
    "set_pose_annotation_context()\n",
    "rr.notebook_show(width=1200, height=700, blueprint=blueprint)\n",
    "\n",
    "for cam_param in exo_data.cam_params_list:\n",
    "    cam_log_path: Path = parent_log_path / cam_param.name   \n",
    "    image_log_path: Path = cam_log_path / \"pinhole\" / \"video\"\n",
    "    # camera parameters don't change, so we can log them once\n",
    "    log_pinhole(\n",
    "                camera=cam_param,\n",
    "                cam_log_path=cam_log_path,\n",
    "                image_plane_distance=0.1,\n",
    "                static=True\n",
    "            )\n",
    "\n",
    "exo_data: ExoData\n",
    "for idx, exo_data in enumerate(sequence):\n",
    "    rr.set_time(\"frame idx\",sequence=idx)\n",
    "\n",
    "    uv_batch_left: None\n",
    "    uv_batch_right: None\n",
    "    for hand_enum in HandSide:\n",
    "        hand_side: Literal[\"left\", \"right\"] = hand_enum.name.lower()\n",
    "        hand_idx: int = hand_enum.value\n",
    "\n",
    "        xyz_gt: Float32[ndarray, \"21 3\"] = exo_data.xyz[hand_idx]\n",
    "\n",
    "        # create a batch of xyz points\n",
    "        xyz_gt_hom: Float[ndarray, \"21 4\"] = np.concatenate([xyz_gt, np.ones_like(xyz_gt)[..., 0:1]], axis=-1)\n",
    "        xyz_gt_hom: Float[Array, \"1 21 4\"] = jnp.array(xyz_gt_hom)[jnp.newaxis, ...]\n",
    "\n",
    "        # create a batch of uv points in vectorized form\n",
    "        uv_batch:Float[Array, \"1 n_views 21 2\"] = proj_3d_vectorized(\n",
    "            xyz_hom=xyz_gt_hom,\n",
    "            P=jnp.array(Pall)\n",
    "        )\n",
    "        # remove the n_frames dimension and convert to numpy\n",
    "        uv_batch = np.array(uv_batch).squeeze(axis=0)\n",
    "        match hand_side:\n",
    "            case \"left\":\n",
    "                uv_batch_left = uv_batch\n",
    "            case \"right\":\n",
    "                uv_batch_right = uv_batch\n",
    "            case _:\n",
    "                raise ValueError(f\"Invalid hand side: {hand_side}\")\n",
    "            \n",
    "        rr.log(\n",
    "            f\"{hand_side}\",\n",
    "            rr.Points3D(\n",
    "                xyz_gt,\n",
    "                colors=(0, 255, 0),\n",
    "                class_ids=0,\n",
    "                keypoint_ids=sequence.hand_ids,\n",
    "                show_labels=False,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    optim_out: tuple[OptimizationResults, LevenbergMarquardtState] = new_joint_and_scale_optimizer(\n",
    "        uv_left_pred_batch=uv_batch_left,\n",
    "        uv_right_pred_batch=uv_batch_right\n",
    "    )\n",
    "    uv_batch_gt:Float[ndarray, \"n_views 2 21 2\"] = np.stack([uv_batch_left, uv_batch_right], axis=1)\n",
    "    optimized_result: OptimizationResults = optim_out[0]\n",
    "\n",
    "    for hand_enum in HandSide:\n",
    "        hand_side: Literal[\"left\", \"right\"] = hand_enum.name.lower()\n",
    "        hand_idx: int = hand_enum.value\n",
    "\n",
    "        match hand_side:\n",
    "            case \"left\":\n",
    "                xyz_optim: Float[ndarray, \"21 3\"] = optimized_result.xyz_mano[0]\n",
    "            case \"right\":\n",
    "                xyz_optim = optimized_result.xyz_mano[1]\n",
    "            case _:\n",
    "                raise ValueError(f\"Invalid hand side: {hand_side}\")\n",
    "        \n",
    "        # project optimized points to 2D\n",
    "        xyz_optim_hom: Float[ndarray, \"21 4\"] = np.concatenate([xyz_optim, np.ones_like(xyz_optim)[..., 0:1]], axis=-1)\n",
    "        xyz_optim_hom: Float[Array, \"1 21 4\"] = jnp.array(xyz_optim_hom)[jnp.newaxis, ...]\n",
    "        uv_optim_batch: Float[Array, \"1 n_views 21 2\"] = proj_3d_vectorized(\n",
    "            xyz_hom=jnp.array(xyz_optim_hom),\n",
    "            P=jnp.array(Pall)\n",
    "        )\n",
    "        # remove the n_frames dimension\n",
    "        uv_optim_batch: Float[ndarray, \"n_views 21 2\"] = np.array(uv_optim_batch).squeeze(axis=0)\n",
    "\n",
    "        rr.log(\n",
    "            f\"{hand_side}_optim\",\n",
    "            rr.Points3D(\n",
    "                xyz_optim,\n",
    "                colors=(0, 255, 0),\n",
    "                class_ids=1,\n",
    "                keypoint_ids=sequence.hand_ids,\n",
    "                show_labels=False,\n",
    "            ),\n",
    "        )\n",
    "        # log the optimized 2D points\n",
    "        for cam_param, uv_optim, uv_gt in zip(exo_data.cam_params_list, uv_optim_batch, uv_batch_gt, strict=True):\n",
    "            cam_log_path: Path = parent_log_path / cam_param.name   \n",
    "            image_log_path: Path = cam_log_path / \"pinhole\" / \"video\"\n",
    "\n",
    "            rr.log(\n",
    "                f\"{image_log_path}/{hand_side}_keypoints_optim\",\n",
    "                rr.Points2D(\n",
    "                    uv_optim,\n",
    "                    colors=(0, 255, 0),\n",
    "                    class_ids=1,\n",
    "                    keypoint_ids=MEDIAPIPE_IDS,\n",
    "                    show_labels=False,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            rr.log(\n",
    "                f\"{image_log_path}/{hand_side}_keypoints_gt\",\n",
    "                rr.Points2D(\n",
    "                    uv_gt[hand_idx],\n",
    "                    colors=(0, 255, 0),\n",
    "                    class_ids=0,\n",
    "                    keypoint_ids=MEDIAPIPE_IDS,\n",
    "                    show_labels=False,\n",
    "                ),\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad9309b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
